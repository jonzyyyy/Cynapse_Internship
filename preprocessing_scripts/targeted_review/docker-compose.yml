services:
  pytorch:
    build:
      context: .
      dockerfile: Dockerfile
    shm_size: 40g
    privileged: true
    ipc: host
    runtime: nvidia
    gpus: all
    ports:
      - 6008:6008
    environment:
      - CUDA_VISIBLE_DEVICES=3
      - PUID=1000
      - PGID=1000
      - TORCH_DISTRIBUTED_DEBUG=DETAIL
      - HF_HOME=/app/cache/huggingface
    volumes:
      - /mnt/nas/TAmob/preprocessing_scripts/targeted_review:/app
      # app/data is the directory that should contain the training data (usually ends with _labeled, if labeled by GroundingDino) 
      - /mnt/nas/TAmob/old_data/final_extracted_frames/23_05_2025 20_29_59 (UTC+03_00)_processed_fr10_10_197_21_23/_labeled/:/app/data
      - /mnt/nas/TAmob/cache:/app/cache 
    tmpfs:
      - /tmp
    command: >
      python3 /app/pipeline.py
      --input_and_label_dir "/app/data"
      --class_map_json "/app/class_map.json"
      --output_folder "/app/pipeline_output3"
      --batch_size 8
      --subset Train
#     --diversified_csvs "/app/modelA_preds.csv" "/app/modelB_preds.csv"